{"cells":[{"source":"# Prompt Engineering with GPT and LangChain","metadata":{},"id":"a6d014ee-e3b7-409c-948b-ac0152f49563","cell_type":"markdown"},{"source":"LangChain is framework that is extremely helpful for prompt engineering and the integration of generative AI capabilities in applications or data platforms. It has many capabilities, some of which will not be introduced until later modules, but we will start with a gentle introduction to some of the easy-to-understand concepts in the framework.\n\nYou'll build an AI agent that uses Python and GPT to perform sentiment analysis on financial headlines.\n\nIn more detail, you'll cover:\n- Getting set up with an OpenAI developer account and integration with Workspace.\n- Interacting with OpenAI models through the langchain framework.\n- Using prompt templates that write reusable, dynamic prompts.\n- Working with LLM chains.\n- Automatically parsing the output of an LLM to be used downstream.\n- Working with langchain agents and tools.\n- Using the OpenAI Moderation API to filter explicit content.\n\nFor this project, we are using two small samples: `financial_headlines.txt` and `reddit_comments.txt`. These 5-6 line samples are kept short to keep evaluation easy, but keep in mind that this same code and prompt engineering techniques can scale to datasets of much larger size.","metadata":{},"id":"9a610d9c-089e-4b41-803d-17024f68c51a","cell_type":"markdown"},{"source":"### Maintenance note, May 2024\n\nSince this code-along was released, the Python packages for working with the OpenAI API have changed their syntax. The instructions, hints, and code have been updated to use the latest syntax, but the video has not been updated. Consequently, it is now slightly out of sync. Trust the workbook, not the video.","metadata":{},"id":"53f4dc65-1735-404a-9b45-a41f62c7c279","cell_type":"markdown"},{"source":"### Before you begin","metadata":{},"id":"9358e4e8-7bba-4f77-a4c1-80a49c57869e","cell_type":"markdown"},{"source":"You'll need a developer account with OpenAI.\n\nSee getting-started.ipynb for steps on how to create an API key and store it in Workspace. In particular, you'll need to follow the instructions in the \"Getting started with OpenAI\" and \"Setting up Workspace Integrations\" sections.","metadata":{},"id":"51a7c002-1011-401e-b7f1-c8f92cee40a8","cell_type":"markdown"},{"source":"## Task 0: Setup","metadata":{},"id":"833b24bb-221d-4d34-9927-8b83496fb65d","cell_type":"markdown"},{"source":"We need to install a few packages, one of which being the `langchain` package. This is currently being developed quickly, sometimes with breaking changes, so we fix the version.\n\n`langchain` depends on a recent version of `typing_extensions`, so we need to update that package, again fixing the version.","metadata":{},"id":"2c4850c8-97f7-4389-96c6-9f44ecbfd06d","cell_type":"markdown"},{"source":"### Instructions\n\nRun the following code to install `openai`, `langchain`, `langchain-openai`, `langchain-experimental`, `typing_extensions` and `pandas`.","metadata":{},"id":"115b1f8e-55a2-471e-8c45-0eaf3e685a44","cell_type":"markdown"},{"source":"# Install the openai package, locked to version 1.27\n!pip install openai==1.27\n\n# Install the langchain package, locked to version 0.1.19\n!pip install langchain==0.1.19\n\n# Install the langchain-openai package, locked to version 0.1.6\n!pip install langchain-openai==0.1.6\n\n# Install the langchain-experimental package, locked to version 0.0.58\n!pip install langchain-experimental==0.0.58\n\n# Update the typing_extensions package, locked to version 4.11.0\n!pip install typing_extensions==4.11.0","metadata":{"executionCancelledAt":null,"executionTime":34901,"lastExecutedAt":1715609671271,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Install the openai package, locked to version 1.27\n!pip install openai==1.27\n\n# Install the langchain package, locked to version 0.1.19\n!pip install langchain==0.1.19\n\n# Install the langchain-openai package, locked to version 0.1.6\n!pip install langchain-openai==0.1.6\n\n# Install the langchain-experimental package, locked to version 0.0.58\n!pip install langchain-experimental==0.0.58\n\n# Update the typing_extensions package, locked to version 4.11.0\n!pip install typing_extensions==4.11.0","outputsMetadata":{"0":{"height":374,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"4de2a21d-1d16-4bef-b401-64760a2b9735","cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting openai==1.27\n  Downloading openai-1.27.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (4.3.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.27) (1.7.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (2.6.4)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (4.66.2)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (4.10.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.27) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.27) (1.2.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.27) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.27) (1.0.4)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.27) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.27) (0.6.0)\nRequirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.27) (2.16.3)\nDownloading openai-1.27.0-py3-none-any.whl (314 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: openai\n\u001b[33m  WARNING: The script openai is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0mSuccessfully installed openai-1.27.0\nDefaulting to user installation because normal site-packages is not writeable\nCollecting langchain==0.1.19\n  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.0.28)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (3.9.3)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (4.0.3)\nCollecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.19)\n  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\nCollecting langchain-community<0.1,>=0.0.38 (from langchain==0.1.19)\n  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\nCollecting langchain-core<0.2.0,>=0.1.52 (from langchain==0.1.19)\n  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.19)\n  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.19)\n  Downloading langsmith-0.1.57-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.6.4)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (8.2.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.9.4)\nCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19) (0.9.0)\nCollecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19)\n  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (0.6.0)\nRequirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (2.16.3)\nRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (4.10.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.19) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain==0.1.19) (2.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.19) (1.0.0)\nDownloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\nDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\nDownloading langsmith-0.1.57-py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, jsonpatch, marshmallow, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n\u001b[33m  WARNING: The script langsmith is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0mSuccessfully installed dataclasses-json-0.6.6 jsonpatch-1.33 langchain-0.1.19 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.1 langsmith-0.1.57 marshmallow-3.21.2 orjson-3.10.3 packaging-23.2\nDefaulting to user installation because normal site-packages is not writeable\nCollecting langchain-openai==0.1.6\n  Downloading langchain_openai-0.1.6-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.46 in /home/repl/.local/lib/python3.10/site-packages (from langchain-openai==0.1.6) (0.1.52)\nRequirement already satisfied: openai<2.0.0,>=1.24.0 in /home/repl/.local/lib/python3.10/site-packages (from langchain-openai==0.1.6) (1.27.0)\nCollecting tiktoken<1,>=0.5.2 (from langchain-openai==0.1.6)\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /home/repl/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/repl/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (0.1.57)\nRequirement already satisfied: packaging<24.0,>=23.2 in /home/repl/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (23.2)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (2.6.4)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (8.2.3)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.3.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.7.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (0.27.0)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.66.2)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.10.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2.31.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.2.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.0.4)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (2.4)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/repl/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (3.10.3)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (0.6.0)\nRequirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (2.16.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (1.26.18)\nDownloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\nDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\nSuccessfully installed langchain-openai-0.1.6 tiktoken-0.6.0\nDefaulting to user installation because normal site-packages is not writeable\nCollecting langchain-experimental==0.0.58\n  Downloading langchain_experimental-0.0.58-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: langchain<0.2.0,>=0.1.17 in /home/repl/.local/lib/python3.10/site-packages (from langchain-experimental==0.0.58) (0.1.19)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /home/repl/.local/lib/python3.10/site-packages (from langchain-experimental==0.0.58) (0.1.52)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.0.28)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.9.3)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/repl/.local/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.6.6)\nRequirement already satisfied: langchain-community<0.1,>=0.0.38 in /home/repl/.local/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.0.38)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /home/repl/.local/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.0.1)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/repl/.local/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.1.57)\nRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.6.4)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (8.2.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /home/repl/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain-experimental==0.0.58) (1.33)\nRequirement already satisfied: packaging<24.0,>=23.2 in /home/repl/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain-experimental==0.0.58) (23.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.9.4)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/repl/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.21.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain-experimental==0.0.58) (2.4)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/repl/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.10.3)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.6.0)\nRequirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.16.3)\nRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (4.10.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.0.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.0.0)\nDownloading langchain_experimental-0.0.58-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: langchain-experimental\nSuccessfully installed langchain-experimental-0.0.58\nDefaulting to user installation because normal site-packages is not writeable\nCollecting typing_extensions==4.11.0\n  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\nDownloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\nInstalling collected packages: typing_extensions\nSuccessfully installed typing_extensions-4.11.0\n"}]},{"source":"For this project, we need first need to load the openai and os packages to set the API key from the environment variables you just created.","metadata":{},"id":"be271ab6-b977-45b3-8b5d-f86b73e9fd2b","cell_type":"markdown"},{"source":"### Instructions\n\n- Import the `os` package.\n- Import the `openai` package.\n- Set `openai.api_key` to the `OPENAI_API_KEY` environment variable.","metadata":{},"id":"30c2c737-4fd2-4a6a-b9c0-710118699d86","cell_type":"markdown"},{"source":"# Import the os package\nimport os\n\n# Import the openai package\nimport openai\n\n# Set openai.api_key to the OPENAI_API_KEY environment variable\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]","metadata":{"executionCancelledAt":null,"executionTime":2079,"lastExecutedAt":1715609673351,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the os package\nimport os\n\n# Import the openai package\nimport openai\n\n# Set openai.api_key to the OPENAI_API_KEY environment variable\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]"},"id":"2d301524-67c0-4894-8e2a-72787de3c9bc","cell_type":"code","execution_count":2,"outputs":[]},{"source":"For the `langchain` package, let's start by importing it's `OpenAI` and `ChatOpenAI` class, which are used to interact with completion models and chat completion models respectively.\n\nCompletion models, such as the GPT-1, GPT-2, GPT-3 and GPT-3.5, work as an advanced autocomplete model. Given a certain snippet of text as input, they will complete the text until a certain point. This could be either an end-of-sequence token (a natural way of stopping), the model reaching its maximum token limit for outputs and so on.\n\nChat completion models, such as GPT-3.5-Turbo (the ChatGPT model) and GPT-4, are designed for conversational use. These models are typically more fine-tuned for conversations, keep a prompt/conversation history and allow access to a system message, which we can use as a meta prompt to define a role, a tone of voice, a scope, etc.\n\nCompletion models and chat completion models tend to work with different classes and functions in the SDK. For that reason, we will start by importing both classes.","metadata":{},"id":"8fa361c0-da75-42f5-84c7-142ed2307c20","cell_type":"markdown"},{"source":"### Instructions\n\n- Import `OpenAI` and `ChatOpenAI` from `langchain_openai`.\n- From the `langchain.prompts` module, import the `PromptTemplate` and `ChatPromptTemplate` classes.\n- From the `langchain.output_parsers` module, import the `CommaSeparatedListOutputParser` class.\n- From the `langchain_experimental.agents.agent_toolkits` module, import `create_python_agent`.\n- From the `langchain_experimental.tools.python.tool` module, import `PythonREPLTool`.","metadata":{},"id":"f18c0e9a-dcc2-4862-895b-e6ecb4347e5f","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nRemember the syntax for Python imports: `from ... import ...`\n\n</p>\n</details>","metadata":{},"id":"b0e7d533-4a77-4c17-a9c2-22b4a76b458f","cell_type":"markdown"},{"source":"# From langchain_openai, import OpenAI, ChatOpenAI\nfrom langchain_openai import OpenAI, ChatOpenAI\n\n# From langchain.prompts, import PromptTemplate, ChatPromptTemplate\nfrom langchain.prompts import PromptTemplate, ChatPromptTemplate\n\n# From langchain.output_parsers, import CommaSeparatedListOutputParser\nfrom langchain.output_parsers import CommaSeparatedListOutputParser\n\n# From langchain_experimental.agents.agent_toolkits, import create_python_agent\nfrom langchain_experimental.agents.agent_toolkits import create_python_agent\n\n# From langchain_experimental.tools.python.tool, import PythonREPLTool\nfrom langchain_experimental.tools.python.tool import PythonREPLTool","metadata":{"executionCancelledAt":null,"executionTime":832,"lastExecutedAt":1715609674184,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# From langchain_openai, import OpenAI, ChatOpenAI\nfrom langchain_openai import OpenAI, ChatOpenAI\n\n# From langchain.prompts, import PromptTemplate, ChatPromptTemplate\nfrom langchain.prompts import PromptTemplate, ChatPromptTemplate\n\n# From langchain.output_parsers, import CommaSeparatedListOutputParser\nfrom langchain.output_parsers import CommaSeparatedListOutputParser\n\n# From langchain_experimental.agents.agent_toolkits, import create_python_agent\nfrom langchain_experimental.agents.agent_toolkits import create_python_agent\n\n# From langchain_experimental.tools.python.tool, import PythonREPLTool\nfrom langchain_experimental.tools.python.tool import PythonREPLTool"},"id":"e08d7737-e753-4e54-9ae4-b65e365bf36f","cell_type":"code","execution_count":3,"outputs":[]},{"source":"## Task 1: Import the Financial News Headlines Data","metadata":{},"id":"303fc31e-5f83-41a3-a078-e929a11e8bf0","cell_type":"markdown"},{"source":"A small sample of financial headlines is stored in `financial_headlines.txt`.\n\nOur first step is to read in the text file and store the headlines in a Python list.","metadata":{},"id":"b1c1b04e-0de7-4050-950e-4f64dfc6a58d","cell_type":"markdown"},{"source":"### Instructions\n\nImport the text file to a Python list.\n\n- Open `financial_headlines.txt` for reading.\n- Read in the lines using the `.readlines()` method. Assign to `headlines`.\n- Print the sample headlines.","metadata":{},"id":"10678d41-3b1c-4471-9e4c-9b1f32ea038f","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\n- A good way of opening (and automatically closing) a file is using: `with open(file_name, \"r\") as file:`.\n- We can then use the `.readlines()` method on the `file` variable.\n    \n</p>\n</details>","metadata":{},"id":"6afdccc3-7743-4a14-9d98-8aa3b32166be","cell_type":"markdown"},{"source":"# Open the text file and read its lines.\nwith open('financial_headlines.txt', 'r') as data:\n    headlines = data.readlines()\n\n# Print all headlines.\nheadlines","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1715609674234,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Open the text file and read its lines.\nwith open('financial_headlines.txt', 'r') as data:\n    headlines = data.readlines()\n\n# Print all headlines.\nheadlines"},"id":"1b5638c5-9db0-4731-8170-e7b6c1a99697","cell_type":"code","execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\\n\",\n 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\\n',\n 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\\n',\n 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\\n',\n \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\\n\",\n 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']"},"metadata":{},"execution_count":4}]},{"source":"The headlines seem to a bit of whitespace preceding the punctuation, but this does not influence the performance of our large language model.\nYou can also see that every headline ends with a new line (`\\n`).\n\nWe can quickly strip the `\\n` from the end of each headline, as this might improve visibility later down the line, when printing these headlines in a dataframe. ","metadata":{},"id":"7c0a4789-58a1-4546-bb39-c5b540eb8559","cell_type":"markdown"},{"source":"### Instructions\n\nStrip the `\\n` character from the end of every news headline.\n\n- Loop through `headlines` and use the `.strip()` method to remove the `\\n` character from each line.\n- Print the result.","metadata":{},"id":"5c7b522e-32b6-4818-9834-f0c2bbf7f230","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nTo quickly reassign the adjusted elements of our list, we can make use of Python list comprehensions.\n    \nFor example: `new_list = [f(x) for x in list]`\n\n</p>\n</details>","metadata":{},"id":"06c8394a-0d77-4d68-a20a-06c1701a8370","cell_type":"markdown"},{"source":"# Strip the new line character from all headlines\nheadlines = [line.strip(\"\\n\") for line in headlines]\n\n# Print all headlines\nheadlines","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1715609674289,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Strip the new line character from all headlines\nheadlines = [line.strip(\"\\n\") for line in headlines]\n\n# Print all headlines\nheadlines"},"id":"980f8d06-4d48-4fb9-9cab-ac66a8371910","cell_type":"code","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\",\n 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .',\n 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .',\n 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .',\n \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\",\n 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']"},"metadata":{},"execution_count":5}]},{"source":"## Task 2: Setting up Prompt Templates","metadata":{},"id":"f389f489-eddd-45c0-84d7-44dd8f9ca5b3","cell_type":"markdown"},{"source":"During this code-along we are using the OpenAI API to programmatically make requests to a GPT-model. This allows us to automate calls to the model, as would be the case when implementing generative AI functionalities in an application or data transformation process.\n\nIn general, when developing an application, we want our code to be modular, scalable and reusable. How do we this with LLM prompts?\n\nThis is where Prompt Templates come into play! It allows for dynamic prompts, with built-in verification tools on whether all inputs are given (this will ease the load on testing). They can easily be saved, versioned and integrated into the code base of an application.\n\nWe will set up Prompt Templates (from the `langchain` package) to automatically determine financial sentiment from the headlines and extract relevant company names. ","metadata":{},"id":"f9f0adf8-630d-4738-95a2-9a8abc0edd67","cell_type":"markdown"},{"source":"### Usage of Prompt Templates\n\nA prompt template can have dynamic input, which can be added using `{ }`.\n\nExample: `\"Can you give me some suggestions for my trip to {city}?\"`\n\nWe can then format the prompt template by filling in the `city` variable.\n\nCertain prompts that are often reused programmatically in application processes might be very lengthy and can be carefully designed to meet a specific need. For example, if we want the output of a sentiment analysis by the GPT-model to be limited to either positive, negative or neutral (without anything else in the answer), we need to explicitly tell the model within our prompt. In order to not accidentally forget this in any of the future prompts, it is best practice to design and save a prompt template.","metadata":{},"id":"ddb5a5e6-e828-4af4-afb4-767dd2ab798b","cell_type":"markdown"},{"source":"### Types of Prompt Templates\n\nPrompt Templates in Langchain come in two formats:\n- PromptTemplate: this is used for completion models.\n- ChatPromptTemplate: this is used for chat completion models. On top of the normal input prompt, these can hold a system message (meta prompt) and a conversation history.\n\nLet's start by creating a PromptTemplate and ChatPromptTemplate.","metadata":{},"id":"b52a25d6-0bc4-487b-812e-19895b80ea9c","cell_type":"markdown"},{"source":"### Instructions\n\nCreate a Prompt Template to analyze financial sentiment.\n- Create a `PromptTemplate` object by using its `.from_template()` method. Assign to `prompt_template`.\n- For the template argument, use:\n\n```\n\"Analyze the following financial headline for sentiment: {headline}\"\n```\n\n- Format the prompt using its `.format()` method. Let's use our first headline as input. Assign to `formatted_prompt`.\n- Print the formatted prompt.","metadata":{},"id":"82de02d9-6a87-4ea1-9b56-c3f03b463748","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\n`prompt_template.format()` will have one argument called `headline` (as defined in our `PromptTemplate`), where we pass along the first element of our `headlines` list.\n\n</p>\n</details>","metadata":{},"id":"f2cde322-6970-43ef-a916-0af0d8bd47be","cell_type":"markdown"},{"source":"# Create a dynamic template to analyze a single headline\nprompt_template = PromptTemplate.from_template(\n    template=\"Analyze the following financial headline for sentiment: {headline}\",\n)\n\n# Format the prompt template on the first headline of the dataset\nformatted_prompt = prompt_template.format(headline=headlines[0])\n\n# Print the formatted template\nformatted_prompt","metadata":{"executionCancelledAt":null,"executionTime":57,"lastExecutedAt":1715609674346,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a dynamic template to analyze a single headline\nprompt_template = PromptTemplate.from_template(\n    template=\"Analyze the following financial headline for sentiment: {headline}\",\n)\n\n# Format the prompt template on the first headline of the dataset\nformatted_prompt = prompt_template.format(headline=headlines[0])\n\n# Print the formatted template\nformatted_prompt"},"id":"e5c74f6d-fad2-4a52-a2e4-653768d33c33","cell_type":"code","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":"\"Analyze the following financial headline for sentiment: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\""},"metadata":{},"execution_count":6}]},{"source":"Now let's set up a `ChatPromptTemplate`, which are compatible with conversational models like GPT-4 and GPT-3.5-Turbo. When using the ChatPromptTemplate, we have the ability to assign a system message, so let's make use of this.\n\nIn terms of prompt engineering, what we write in the system can heavily influence the quality of the output. Some things we can do using the system message is:\n- Define a role: *\"You are a X\", \"Your role is to do X\", ...*\n- Define a tone of voice: *\"Respond in a formal manner\", \"Use customer-oriented language\", ...*\n- Define restrictions on output format: *\"The format of the output is X\", \"The output is strictly limited to X, Y, Z\", ...*\n- Define a scope: *\"Only answer questions on topic X\", \"If the user questions is not about X, answer with Y\", ...*\n\nYou will notice some of these tricks applied to the following system message.","metadata":{},"id":"d858c71f-a8eb-4115-a747-7bd643595ea5","cell_type":"markdown"},{"source":"### Instructions\n\n- Define a system message as follows and assign to `system_message`.\n\n```\n\"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \nThis sentiment is to be used to advice financial analysts. \nThe format of the output has to be consistent. \nThe output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n```\n\n- Instantiate a new `ChatPromptTemplate` using its `.from_messages()` method. Assign to `chat_template`.\n    - This method will take a list of tuples as input. We need two tuples, one for the system message and one for the human message. To distinguish the two, the first element of the tuple is either `\"system\"` or `\"human\"`.\n    - The second element of the tuple is the actual message, as string. For the system message, you can use the `system_message`variable. For the human message, we can reuse the same message as before (including the input variable `{headlines}`).\n    \n- Format the template using its `.format_messages()` method. Let's use our first headline again. Assign to `formatted_chat_template`.\n- Print the formatted template.","metadata":{},"id":"054ac0a5-48d9-46a8-bc27-412280ea0eee","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nThe input for `ChatPromptTemplate.from_messages()` follows this structure:\n`[(\"system\", system_message), (\"human\", input_prompt)]`\n\n</p>\n</details>","metadata":{},"id":"8636ebd3-e8f2-4b47-b962-bc921e0bced7","cell_type":"markdown"},{"source":"# Define the system message.\nsystem_message = \"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \n    This sentiment is to be used to advice financial analysts. \n    The format of the output has to be consistent. \n    The output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n\n# Initialize a new ChatPromptTemplate with a system message and human message.\nchat_template = ChatPromptTemplate.from_messages([\n    (\"system\", system_message),\n    (\"human\", \"Analyze the following financial headline for sentiment: {headline}\"),\n])\n\n# Format the ChatPromptTemplate.\nformatted_chat_template = chat_template.format_messages(\n    headline=headlines[0]\n)\n\n# Print the formatted template.\nformatted_chat_template","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1715609674401,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the system message.\nsystem_message = \"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \n    This sentiment is to be used to advice financial analysts. \n    The format of the output has to be consistent. \n    The output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n\n# Initialize a new ChatPromptTemplate with a system message and human message.\nchat_template = ChatPromptTemplate.from_messages([\n    (\"system\", system_message),\n    (\"human\", \"Analyze the following financial headline for sentiment: {headline}\"),\n])\n\n# Format the ChatPromptTemplate.\nformatted_chat_template = chat_template.format_messages(\n    headline=headlines[0]\n)\n\n# Print the formatted template.\nformatted_chat_template"},"id":"2d621445-3804-442d-8040-8405c6c9c83f","cell_type":"code","execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[SystemMessage(content='You are performing sentiment analysis on news headlines regarding financial analysis. \\n    This sentiment is to be used to advice financial analysts. \\n    The format of the output has to be consistent. \\n    The output is strictly limited to any of the following options: [positive, negative, neutral].'),\n HumanMessage(content=\"Analyze the following financial headline for sentiment: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\")]"},"metadata":{},"execution_count":7}]},{"source":"## Task 3: Setting up LLM Chains","metadata":{},"id":"ec62e063-c2bf-42c9-bb54-f774e3f13ff2","cell_type":"markdown"},{"source":"We will briefly cover the concept of chains in langchain. LLM Chains are an easy way to combine a model with a prompt template. These chains can be created for both *completion models* and *chat completion models*.\n\nLLM Chains can be used to \"chain\" prompt flows, by using the output of a previous chain as input for the next.\n\nLet's set up a chain for a completion model first, using the templates that we've just built.","metadata":{},"id":"907abbe1-0ecb-4b33-8a46-8471c214df38","cell_type":"markdown"},{"source":"### Instructions\n\nCreate an LLM chain for a completion model.\n- Define an `OpenAI()` client model. Assign to `client`.\n- Pipe the prompt template to the client. Assign to `completion_chain`.\n- Invoke `completion_chain`, setting the headline variable to the first element of the `headlines` list.","metadata":{},"id":"a597b3fb-9710-4054-a0cc-a0541cfb3f4a","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nTo create an LLM chain, you pipe the template to the client model.\n    \n```py\nchain = prompt | client\n```\n\n---\n\nTo pass the prompt to GPT and get a response, you invoke the chain with `.invoke()`. This takes a dictionary argument containing the  names and values of the variables you want to pass into the template.\n    \n```py\nchain.invoke({\"key\": value})\n```\n\n</p>\n</details>","metadata":{},"id":"1cd2b555-1edb-414c-8460-7e28c7ec7b8a","cell_type":"markdown"},{"source":"# Define a client model. Assign to client.\nclient = OpenAI()\n\n# Pipe the prompt template to the client. Assign to completion_chain.\ncompletion_chain = prompt_template | client\n\n# Invoke completion_chain, setting the headline variable to the first headline\ncompletion_chain.invoke({\"headline\": headlines[0]})","metadata":{"executionCancelledAt":null,"executionTime":459,"lastExecutedAt":1715609674860,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define a client model. Assign to client.\nclient = OpenAI()\n\n# Pipe the prompt template to the client. Assign to completion_chain.\ncompletion_chain = prompt_template | client\n\n# Invoke completion_chain, setting the headline variable to the first headline\ncompletion_chain.invoke({\"headline\": headlines[0]})"},"id":"234126d2-0e6a-4286-8fd9-2ec95eb5a566","cell_type":"code","execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":"'\\n\\nPositive'"},"metadata":{},"execution_count":8}]},{"source":"Now let's do the same, using a chat completion model.","metadata":{},"id":"20424b97-c01c-4786-9460-beae26fb8a35","cell_type":"markdown"},{"source":"### Instructions\n\n- Define a chat client model. Assign to `chat`.\n- Pipe the chat template to the client. Assign to `chat_chain`.\n- Invoke `chat_chain`, setting the headline to the first element of `headlines`. In the additioanl arguments, set `system_message` to `system_message`.","metadata":{},"id":"e834ad2f-299b-4834-8e05-56eb0b67e99e","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\n`chat_chain.invoke()` takes a dictionary input variable, and the system message can also be passed as a dictionary.\n    \n```py\nchain.invoke(input_dict, {\"system_message\": system_message})\n```\n\n</p>\n</details>","metadata":{},"id":"883ddd72-41e3-426b-b969-74129a1a158d","cell_type":"markdown"},{"source":"# Define a chat client model. Assign to chat.\nchat = ChatOpenAI()\n\n# Pipe the chat template to the client. Assign to chat_chain.\nchat_chain = chat_template | chat\n\n# Invoke chat_chain, setting headline to the first headline and using system_message\nchat_chain.invoke({\"headline\": headlines[0]}, {\"system_message\": system_message})","metadata":{"executionCancelledAt":null,"executionTime":557,"lastExecutedAt":1715609675417,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define a chat client model. Assign to chat.\nchat = ChatOpenAI()\n\n# Pipe the chat template to the client. Assign to chat_chain.\nchat_chain = chat_template | chat\n\n# Invoke chat_chain, setting headline to the first headline and using system_message\nchat_chain.invoke({\"headline\": headlines[0]}, {\"system_message\": system_message})"},"id":"00a8db2b-fd72-421c-9e17-82a47ee460b5","cell_type":"code","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":"AIMessage(content='Positive', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 118, 'total_tokens': 119}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a970c076-e1a3-4972-b487-7e891fe702b4-0')"},"metadata":{},"execution_count":9}]},{"source":"## Task 4: Extracting Company Names with the Output Parser","metadata":{},"id":"b55de8b3-7e57-4fcb-b160-462b22828122","cell_type":"markdown"},{"source":"Output parsing is a very useful feature in Langchain when integrating LLM outputs into your application. The output parser can automatically transform the output of the GPT-model to numerous data types, such as lists, datetimes, JSONs and so on.\n\nIn this example, we will ask the GPT-model to extract the company name from every headline and instantly assign them to a Python list.\n\nAs we want to combine sentiment with the company name later, we will limit the output to one name per headline.\n\nIn order to format the output as a Python list, we can make use of the `CommaSeparatedListOutputParser` class in Langchain.","metadata":{},"id":"b5c74f27-1a7a-43f8-b0c1-04bfc9611f0f","cell_type":"markdown"},{"source":"### Instructions\n\nCreate an output parser and a formatted prompt template to extract company names from multiple headlines.\n- Instantiate a new `CommaSeparatedListOutputParser` and assign to `output_parser`.\n- To retrieve the parsing instructions from the output parser, we can use its `.get_format_instructions()` method. Assign this to `format_instructions`.\n- Let's instantiate a new `PromptTemplate`. This time we won't use its `.from_template()` method. When calling `PromptTemplate()` with the output parser, we need to pass three arguments:\n    - `template`: here we can use the following string; \n```\n\"List all the company names from the following headlines, limited to one name per headline: {headlines}.\\n{format_instructions}\"\n```\n\n- `input_variables`: This is a list of strings containing the input variables that are required. In our case, this is only `\"headlines\"`.\n- `partial_variables`: Here we pass along a dictionary with the key being `\"format_instructions\"` and the value being the `format_instructions` variable we created earlier.\n- Format the prompt template using the entire `headlines` list.","metadata":{},"id":"60d62a05-8c14-4d02-b6ed-1d896f222724","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nWe can create a new prompt template using `PromptTemplate(template= , input_variables= , partial_variables= )`\n\n</p>\n</details>","metadata":{},"id":"69682dd4-6bf4-4a4e-a85f-0a6757112956","cell_type":"markdown"},{"source":"# Instantiate the output parser.\noutput_parser = CommaSeparatedListOutputParser()\n\n# Get the format instructions from the output parser.\nformat_instructions = output_parser.get_format_instructions()\n\n# Instantiate a new prompt template with the format instructions.\ncompany_name_template = PromptTemplate(\n    template=\"List all the company names from the following headlines, limited to one name per headline: {headlines}.\\n{format_instructions}\",\n    input_variables=[\"headlines\"],\n    partial_variables={\"format_instructions\": format_instructions}\n)\n\n# Format the prompt using all headlines.\nformatted_company_name_template = company_name_template.format(headlines=headlines)","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1715609675466,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate the output parser.\noutput_parser = CommaSeparatedListOutputParser()\n\n# Get the format instructions from the output parser.\nformat_instructions = output_parser.get_format_instructions()\n\n# Instantiate a new prompt template with the format instructions.\ncompany_name_template = PromptTemplate(\n    template=\"List all the company names from the following headlines, limited to one name per headline: {headlines}.\\n{format_instructions}\",\n    input_variables=[\"headlines\"],\n    partial_variables={\"format_instructions\": format_instructions}\n)\n\n# Format the prompt using all headlines.\nformatted_company_name_template = company_name_template.format(headlines=headlines)"},"id":"6cac36e4-9d98-414e-8204-848c299a3457","cell_type":"code","execution_count":10,"outputs":[]},{"source":"Now that we have a template with format instructions ready, let's send it to a GPT-model and look at the output. We want to run these kinds of tasks with the temperature parameter of the large language model set to zero, as this maximizes precision. \n\nWe tend to distinguish tasks that either require precision or creativity. When we are looking for correctness in the answer (e.g. when generating code) we aim for high precision (by lowering temperature) whereas when generating ideas or content, we might prefer more creativity (by increasing temperature). A simplified explanation of the *temperature* of a large language model is its randomness. When temperature is set to 0, we will get the exact same output, given the same inputs.","metadata":{},"id":"54576b7b-2048-49f6-939c-ced2c8a834d9","cell_type":"markdown"},{"source":"**Instructions**\n\nCreate a new Langchain model, send over the template and inspect the parsed output.\n- Instantiate a new `OpenAI()` client model. Set the temperature to 0. Assign to `model`.\n- Invoke `model` on the formatted template. Assign to `_output`. The underscore preceding our variable name indicates that this is just a temporary variable, that will likely be overwritten many times.\n- Use the `.parse()` method of the output parser on the output of the model. Assign to `company_names`.\n- Print the data type of `company_names`.\n- Print the company names.","metadata":{},"id":"e00a6e04-c726-4dc1-a240-9f0b3291de28","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\n- The temperature of the model can be set to 0 by using `OpenAI(temperature= )`.\n- We can get the data type of a variable by using `type(variable)`.\n\n</p>\n</details>","metadata":{},"id":"20ea561c-9b4f-4e6c-a630-eef71d2fc43d","cell_type":"markdown"},{"source":"# Instantiate a Langchain OpenAI Model object.\nmodel = OpenAI(temperature=0)\n\n# Invoke the model on the input.\n_output = model.invoke(formatted_company_name_template)\n\n# Parse the output.\ncompany_names = output_parser.parse(_output)\n\n# Print the data type the parsed output.\nprint(f\"Data type: {type(company_names)}\\n\")\n\n# Print the output.\nprint(company_names)","metadata":{"executionCancelledAt":null,"executionTime":978,"lastExecutedAt":1715609676444,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate a Langchain OpenAI Model object.\nmodel = OpenAI(temperature=0)\n\n# Invoke the model on the input.\n_output = model.invoke(formatted_company_name_template)\n\n# Parse the output.\ncompany_names = output_parser.parse(_output)\n\n# Print the data type the parsed output.\nprint(f\"Data type: {type(company_names)}\\n\")\n\n# Print the output.\nprint(company_names)","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"id":"f1dde4f8-ccb5-4bf0-a7d6-35f1a1f6e66a","cell_type":"code","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":"Data type: <class 'list'>\n\n['Aktia Group', 'Vaisala Oyj', 'Orion', 'Tiimari', 'Metso Paper', 'Outokumpu Technology']\n"}]},{"source":"## Task 5: Working with Agents and Tools","metadata":{},"id":"f8ab6d2c-87d1-4966-bac0-99f3ba39d195","cell_type":"markdown"},{"source":"Leveraging the agents and tools in LangChain is where the framework's value really starts to shine! But before we dive deeper into this concept, we need to understand MRKL prompts.","metadata":{},"id":"fa5daf04-5793-4fdc-a6d8-268430d7ab17","cell_type":"markdown"},{"source":"### What are MRKL Prompts?\n\nMRKL stands for Modular Reasoning, Knowledge and Language prompts. It is a system composed of a set of modules, often accompanied by an agent that decides how to route prompts to the appropriate module (or tools).\n\nThese kinds of prompts follow a specific format, which we can force the GPT-model to adhere to by using the system message. It will loop through this format (steps 1-5 below) using recursive requests to the GPT-model until we get our final answer. A commonly used format is the following:\n1. Question: the user question (in the first iteration) or follow-up question composed by the GPT-models (in later iterations)\n2. Thought: think about what to do as a next step\n3. Action: pick a tool from the list of tool names we have provided\n4. Action Input: the input for the chosen tool\n5. Observation: the output of the tool","metadata":{},"id":"c8f4e729-a8e9-4d28-bc3f-752cb3efc620","cell_type":"markdown"},{"source":"### What are Tools and Agents?\n\nWe can access (external) tools using the output of the GPT-model. Large language models output only text. In order to call a function (to access a tool) based on the text output of a large language model, we can use agents. They can parse the text output, pick the correct tool and define its input.\n\nThe langchain framework has a wide variety of built-in tools, along with the ability to define additional custom tools. A very common use case for tools is accessing document stores or vector databases to ingest information from our own documents. This will be explored more in-depth in future modules.\n\nFor now, to have a gentle introduction to tools, we have decided on one that does not require external set up (no API token that needs to be created or external database that needs to be set up). \n\nIn this example, we will make use of the `PythonREPLTool`. This allows the GPT-model to run the Python code that it generates, and can be useful for carrying out an abundance of tasks.\n\nNote: as we introduce recursive prompts using agents, it is best practice to always define a maximum number of output tokens. This ensures our costs will not skyrocket if a prompt loop takes too long.","metadata":{},"id":"709a8d80-fb26-4f83-9cf2-19e6cbb00557","cell_type":"markdown"},{"source":"### Instructions\n\nBefore we continue with our financial analysis, let's create a quick example of how code can be ran using a Python agent. In this case, we will ask it to make a calculation (something that most large language models are not trained to do out-of-the-box).\n- Create a Python agent by calling the `create_python_agent()` function. Assign to `agent_executor`. This function takes three arguments:\n    - `llm`: here we can create a new `OpenAI()` model. Let's set the `temperature` to 0 and `max_tokens` to 1000.\n    - `tool`: here we instantiate a new `PythonREPLTool()`.\n    - `verbose`: set this to True so that can we see the prompt loop.\n- Invoke the agent using its `.invoke()` method. As an example, you can ask it: `\"What is the square root of 250? Round the answer down to 4 decimals.\"`","metadata":{},"id":"7234a5ec-0f44-4ca6-9d2e-0a983386b7e7","cell_type":"markdown"},{"source":"# Instantiate a Python agent, with the PythonREPLTool.\nagent_executor = create_python_agent(\n    llm=OpenAI(temperature=0, max_tokens=1000),\n    tool=PythonREPLTool(),\n    verbose=True\n)\n\n# Ask the agent for the solution of a mathematical equation.\nagent_executor.invoke(\"What is the square root of 250? Round the answer down to 4 decimals.\")","metadata":{"executionCancelledAt":null,"executionTime":3070,"lastExecutedAt":1715609679514,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate a Python agent, with the PythonREPLTool.\nagent_executor = create_python_agent(\n    llm=OpenAI(temperature=0, max_tokens=1000),\n    tool=PythonREPLTool(),\n    verbose=True\n)\n\n# Ask the agent for the solution of a mathematical equation.\nagent_executor.invoke(\"What is the square root of 250? Round the answer down to 4 decimals.\")","outputsMetadata":{"0":{"height":416,"type":"stream"}}},"id":"9016d465-16b8-48d8-af78-3384a113eaa3","cell_type":"code","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m I can use the math module to calculate the square root.\nAction: Python_REPL\nAction Input: import math\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m Now that the math module is imported, I can use the sqrt function.\nAction: Python_REPL\nAction Input: math.sqrt(250)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m The result is a float, so I can use the round function to round it down to 4 decimals.\nAction: Python_REPL\nAction Input: round(math.sqrt(250), 4)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer.\nFinal Answer: 15.8114\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"},{"output_type":"execute_result","data":{"text/plain":"{'input': 'What is the square root of 250? Round the answer down to 4 decimals.',\n 'output': '15.8114'}"},"metadata":{},"execution_count":12}]},{"source":"Investigate the output above. As we haven't assigned any other tool, the choice of tools for the model was quite limited. Hence under Action, it should list the `Python_REPL` tool.\nThe Action Input will show the actual code that was generated by the GPT-model and executed by the Agent.\n\nNow let's try to use the same agent to help us in our financial news analysis.\n\nWe want to structure our prompt in a clear way, explaining a step by step process. For example:\n- First, *Analyze the sentiment...*\n- Second, *Load this data into a pandas dataframe.*\n- Third, *Save this dataframe to a CSV under the name financial_analysis.csv*\n- ...\n\nLastly, we pass along the headlines (input data) itself.","metadata":{},"id":"867eb98e-bcc4-4278-a562-94e4ff9072b6","cell_type":"markdown"},{"source":"### Instructions\n\nAsk the agent to extract the company name and sentiment from the headlines and save its output in a `.csv` file called `financial_analysis.csv`.\n- Invoke the agent on the following prompt:\n    \n    ``` \n    f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is positive, neutral or negative. \n    Load this data into a pandas dataframe. \n    The dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \n    The dataframe can then be saved in the current working directory under the name financial_analysis.csv.\n    If a csv file already exists with the same name, it should be overwritten.\n\n    The headlines are the following:\n    {headlines}\"\"\"\n    ```","metadata":{},"id":"044d23e5-930f-4a11-b3ff-fb42e61222cd","cell_type":"markdown"},{"source":"# Invoke the agent\nagent_executor.invoke(f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is   positive, neutral or negative. \n   Load this data into a pandas dataframe. \n   The dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \n   The dataframe can then be saved in the current working directory under the name financial_analysis.csv.\n   If a csv file already exists with the same name, it should be overwritten.\n\n   The headlines are the following:\n   {headlines}\n   \"\"\")","metadata":{"executionCancelledAt":null,"executionTime":10732,"lastExecutedAt":1715609690246,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Invoke the agent\nagent_executor.invoke(f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is   positive, neutral or negative. \n   Load this data into a pandas dataframe. \n   The dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \n   The dataframe can then be saved in the current working directory under the name financial_analysis.csv.\n   If a csv file already exists with the same name, it should be overwritten.\n\n   The headlines are the following:\n   {headlines}\n   \"\"\")","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"d6b142a8-d387-4738-90de-c4d7f7d74fc3","cell_type":"code","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m I need to import the necessary libraries and create a dataframe to store the extracted data.\nAction: Python_REPL\nAction Input: import pandas as pd\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to create a list of the headlines and then loop through each headline to extract the company name and financial sentiment.\nAction: Python_REPL\nAction Input: headlines = [\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .', 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .', 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\", 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to create an empty dataframe with the appropriate column names.\nAction: Python_REPL\nAction Input: df = pd.DataFrame(columns=['Company Name', 'Financial Sentiment', 'Headline'])\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to loop through each headline and extract the company name and financial sentiment.\nAction: Python_REPL\nAction Input: for headline in headlines:\n    if 'Finnish' in headline:\n        company_name = 'Finnish'\n    else:\n        company_name = 'Unknown'\n    if 'profit' in headline or 'revenues' in headline:\n        financial_sentiment = 'Positive'\n    elif 'loss' in headline:\n        financial_sentiment = 'Negative'\n    else:\n        financial_sentiment = 'Neutral'\n    df = df.append({'Company Name': company_name, 'Financial Sentiment': financial_sentiment, 'Headline': headline}, ignore_index=True)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3mAttributeError(\"'DataFrame' object has no attribute 'append'\")\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to use the pandas .loc method to add rows to the dataframe.\nAction: Python_REPL\nAction Input: for headline in headlines:\n    if 'Finnish' in headline:\n        company_name = 'Finnish'\n    else:\n        company_name = 'Unknown'\n    if 'profit' in headline or 'revenues' in headline:\n        financial_sentiment = 'Positive'\n    elif 'loss' in headline:\n        financial_sentiment = 'Negative'\n    else:\n        financial_sentiment = 'Neutral'\n    df.loc[len(df)] = [company_name, financial_sentiment, headline]\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to save the dataframe as a csv file in the current working directory.\nAction: Python_REPL\nAction Input: df.to_csv('financial_analysis.csv', index=False)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer.\nFinal Answer: The dataframe with the extracted data has been saved as financial_analysis.csv in the current working directory.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"},{"output_type":"execute_result","data":{"text/plain":"{'input': 'For every of the following headlines, extract the company name and whether the financial sentiment is   positive, neutral or negative. \\n   Load this data into a pandas dataframe. \\n   The dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \\n   The dataframe can then be saved in the current working directory under the name financial_analysis.csv.\\n   If a csv file already exists with the same name, it should be overwritten.\\n\\n   The headlines are the following:\\n   [\"Finnish Aktia Group \\'s operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", \\'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\\', \\'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\\', \\'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\\', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries \\' ( SFI ) pulp mill in Sabah , Malaysia .\", \\'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\\']\\n   ',\n 'output': 'The dataframe with the extracted data has been saved as financial_analysis.csv in the current working directory.'}"},"metadata":{},"execution_count":13}]},{"source":"Observe the output above. Do you see anything that could be improved? We will come back to this later in this notebook.\n\nFor now, let's quickly load our `.csv` file in a dataframe to analyze.","metadata":{},"id":"f4865a0e-2caf-4242-802f-1553ba1d3b5d","cell_type":"markdown"},{"source":"### Instructions\n\nLoad the data in a dataframe for evaluation.\n- Import `pandas` under its usual alias: `pd`.\n- Load the `financial_analysis.csv` file into a dataframe. Assign to `df`.\n- Print the dataframe. As our dataframe only contains six rows, we can just print the entire dataframe.","metadata":{},"id":"86270b08-e124-43bb-8834-210bdb6c0a43","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nUse the `pd.read_csv(filename)` function to load the `.csv` file to dataframe.\n\n</p>\n</details>","metadata":{},"id":"de02653d-dda5-432a-ba2b-16f5faf0686e","cell_type":"markdown"},{"source":"# Make the necessary import.\nimport pandas as pd\n\n# Load the CSV file into a dataframe.\ndf = pd.read_csv(\"financial_analysis.csv\")\n\n# Print the dataframe.\ndf","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1715609690293,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Make the necessary import.\nimport pandas as pd\n\n# Load the CSV file into a dataframe.\ndf = pd.read_csv(\"financial_analysis.csv\")\n\n# Print the dataframe.\ndf","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{}}}},"id":"e1c01e13-0d39-407d-80f6-f0ebe5f76827","cell_type":"code","execution_count":14,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Company Name","type":"string"},{"name":"Financial Sentiment","type":"string"},{"name":"Headline","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4,5],"Company Name":["Finnish","Finnish","Finnish","Finnish","Finnish","Finnish"],"Financial Sentiment":["Positive","Negative","Positive","Positive","Neutral","Neutral"],"Headline":["Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .","Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .","Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .","Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .","Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .","Finnish Outokumpu Technology has been awarded several new grinding technology contracts ."]}},"total_rows":6,"truncation_type":null},"text/plain":"  Company Name  ...                                           Headline\n0      Finnish  ...  Finnish Aktia Group 's operating profit rose t...\n1      Finnish  ...  Finnish measuring equipment maker Vaisala Oyj ...\n2      Finnish  ...  Finnish pharmaceuticals company Orion reports ...\n3      Finnish  ...  Tiimari , the Finnish retailer , reported to h...\n4      Finnish  ...  Finnish Metso Paper has been awarded a contrac...\n5      Finnish  ...  Finnish Outokumpu Technology has been awarded ...\n\n[6 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Company Name</th>\n      <th>Financial Sentiment</th>\n      <th>Headline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Finnish</td>\n      <td>Positive</td>\n      <td>Finnish Aktia Group 's operating profit rose t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Finnish</td>\n      <td>Negative</td>\n      <td>Finnish measuring equipment maker Vaisala Oyj ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Finnish</td>\n      <td>Positive</td>\n      <td>Finnish pharmaceuticals company Orion reports ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Finnish</td>\n      <td>Positive</td>\n      <td>Tiimari , the Finnish retailer , reported to h...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Finnish</td>\n      <td>Neutral</td>\n      <td>Finnish Metso Paper has been awarded a contrac...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Finnish</td>\n      <td>Neutral</td>\n      <td>Finnish Outokumpu Technology has been awarded ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":14}]},{"source":"When analyzing the output above (looking at the company names and sentiment), you will probably notice some room for improvement. \n\nCompany names and sentiment may not be extracted in a very powerful way. The reason for this is that without further instructions, the GPT-model will use the PythonREPLTool (Python code) to complete its task. Looking back at the output from our last call to the Python agent, we may find that it created rule sets on how to extract the company name or determine the sentiment. These hard-coded rules negate the power of large language models! We will improve on this in Task 7.\n\nAnother problem that might arise is that the *sentiment* of a sentence can differ from *financial sentiment*. For example, an aggressive headline complaining about a large corporation making too much profit might result in negative sentiment, while from a financial analysis point of view the sentiment is positive. To steer the GPT-model to our desired outcome, we will now introduce few shot learning.\n\nFor example, *Company X was awarded a new contract* might be categorized as a neutral sentence. The sentence itself is simply an objective statement or observation. Nothing is mentioned about whether we like or dislike that particular company because of this. From a financial perspective however, this is considered as something positive. To steer the GPT-model to our desired outcome, we will now introduce few shot learning.","metadata":{},"id":"d37d368b-b177-41f9-abe8-dacf99486401","cell_type":"markdown"},{"source":"## Task 6: Adding Few Shot Learning","metadata":{},"id":"31bb73ca-089b-4bdf-ba9f-e2efbe3174f0","cell_type":"markdown"},{"source":"Few shot learning basically comes down to adding some examples into our prompt, in this case, what we consider to be positive or negative headlines. A shot refers to an example given to the model in the input prompt (or sometimes the system message).\n\nWe distinguish three categories of contextual learning:\n- Few shot leaning (multiple examples)\n- Single shot learning (one example)\n- Zero shot leaning (no examples)\n\nFew shot learning might take more effort in terms of prompt building, but it will generally yield better results, as the model has a better understanding of our desired outcome.\n\nLet's look at an example of financial sentiment analysis without few shot learning first.","metadata":{},"id":"cbe98ba4-9d30-40e7-8a80-d8b780a48105","cell_type":"markdown"},{"source":"### Instructions\n\nCreate a prompt template with output parsing to determine the financial sentiment of all headlines.\n- Create a new `PromptTemplate` called `sentiment_template`. Remember the three arguments `template`, `input_variables` and `partial_variables`. Assign to `sentiment_template`.\n    - We can reuse the `format_instructions` variable that we have loaded into memory before.\n    - As a template, use: \n```\n\"Get the financial sentiment of each of the following headlines. The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\"\n```\n\n\n- Format the template on all headlines. Assign to `formatted_sentiment_template`.\n- Run the formatted template by invoking our `model` and assign the result to our temporary variable `_output`.\n- Parse the output using the output parser. Assign the result to `sentiments`.\n- Print the sentiments.","metadata":{},"id":"59658d1d-3b7c-4e7c-8521-c295982c3de7","cell_type":"markdown"},{"source":"# Create a new prompt template with output parsing.\nsentiment_template = PromptTemplate(\n    template=\"Get the financial sentiment of each of the following headlines. The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n    input_variables=[\"headlines\"],\n    partial_variables={\"format_instructions\": format_instructions}\n)\n\n# Format the prompt template.\nformatted_sentiment_template = sentiment_template.format(headlines=headlines)\n\n# Invoke the model on the formatted prompt template.\n_output = model.invoke(formatted_sentiment_template)\n\n# Parse the output.\nsentiments = output_parser.parse(_output)\n\n# Print the list of sentiments.\nsentiments","metadata":{"executionCancelledAt":null,"executionTime":410,"lastExecutedAt":1715609690704,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a new prompt template with output parsing.\nsentiment_template = PromptTemplate(\n    template=\"Get the financial sentiment of each of the following headlines. The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n    input_variables=[\"headlines\"],\n    partial_variables={\"format_instructions\": format_instructions}\n)\n\n# Format the prompt template.\nformatted_sentiment_template = sentiment_template.format(headlines=headlines)\n\n# Invoke the model on the formatted prompt template.\n_output = model.invoke(formatted_sentiment_template)\n\n# Parse the output.\nsentiments = output_parser.parse(_output)\n\n# Print the list of sentiments.\nsentiments"},"id":"30dc1956-488a-4c93-a887-a5ea803f30a4","cell_type":"code","execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":"['Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive']"},"metadata":{},"execution_count":15}]},{"source":"It is hard to evaluate the sentiments without seeing the associated headline. To make our lives easier, let's write a quick function to easily visualize and interpret the result.","metadata":{},"id":"843f4c4d-8185-4ebe-991b-1d179cc5e15a","cell_type":"markdown"},{"source":"### Instructions\n\nVisualize and interpret the results of the sentiment analysis.\n- Write a function called `visualize_sentiments` to visualize both the sentiment and associated headline, for all headlines. \n    - The input for this function should be two lists: one containing all headlines and one containing all sentiments.\n    - As a best practice, start with using an `assert` that ensures that both lists are of equal length.\n    - There are many ways to create this: simply printing with f-strings, making a dictionary or Dataframe, get creative!\n- Call the `visualize_sentiments` function using `headlines` and `sentiments` as input.","metadata":{},"id":"da3d6834-6c1e-4542-80f3-dc1b385f6477","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\n- We can assert that both input lists are of equal length by using `assert len(list1) == len(list2)`.\n- A very simplistic way of visualizing the sentiments per headline is using f-strings, such as `f\"{sentiments[i]}: {headlines[i]}\"` in a loop. \n\n</p>\n</details>","metadata":{},"id":"5bf24583-5de7-45fb-849b-16db6d86b724","cell_type":"markdown"},{"source":"# Define a new function with two inputs,\ndef visualize_sentiments(headlines, sentiments):\n    # Assert that both inputs are of equal length\n    assert len(headlines) == len(sentiments)\n\n    # Visualize the sentiments and their respective headlines\n    for i, _ in enumerate(headlines):\n        print(f\"{sentiments[i].upper()}: {headlines[i]}\")\n\n# Call the function\nvisualize_sentiments(headlines, sentiments)","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1715609690754,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define a new function with two inputs,\ndef visualize_sentiments(headlines, sentiments):\n    # Assert that both inputs are of equal length\n    assert len(headlines) == len(sentiments)\n\n    # Visualize the sentiments and their respective headlines\n    for i, _ in enumerate(headlines):\n        print(f\"{sentiments[i].upper()}: {headlines[i]}\")\n\n# Call the function\nvisualize_sentiments(headlines, sentiments)","outputsMetadata":{"0":{"height":269,"type":"stream"}}},"id":"4e7ca1a7-4249-4826-ac57-5093ee3de9d1","cell_type":"code","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"POSITIVE: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\nNEGATIVE: Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\nPOSITIVE: Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\nPOSITIVE: Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\nPOSITIVE: Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\nPOSITIVE: Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\n"}]},{"source":"Now we might see that the financial sentiment is not always correctly assigned, such as a contract being awarded not being recognized as a financially positive headline.\nTo improve the performance, we will add some examples. Few shot learning can be done by either giving some observations (headlines in this case) accompanied by their ground truth (label) *or* by giving an abstract description of what is seen as positive, negative or neutral.\n\nIn this case, we will opt for the later. Here is a prompt you can use for few shot learning:\n\n```\n\"\"\"\nIf a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\nIf the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\nIf nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n\"\"\"\n```","metadata":{},"id":"3bc7af8c-461c-42d2-ae37-2da14438c5c6","cell_type":"markdown"},{"source":"### Instructions\n\nCreate and run a prompt template using few shot learning.\n- Store the prompt above in a variable called `sentiment_examples`.\n- Create a `PromptTemplate` called `sentiment_template` like we did two cells above.\n    - In our template, we will add a new input variable called `few_shot_examples`. This can be placed in between the two sentences.\n    - Don't forget to add our new input variables to the list of `input_variables`.\n    - Reuse the same `format_instructions` as before.\n- Format the `sentiment_template`. Remember that you will need to pass both `headlines` and `sentiment_examples`.\n- Run the formatted template by invoking our `model` and assign the result to our temporary variable `_output`.\n- Parse the output using the output parser. Assign the result to `sentiments`.\n- Visualize and interpret the results using your newly created `visualize_sentiments` function.","metadata":{},"id":"3142596a-b723-4d4f-9d2d-2066531aeea6","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nThe `template` we should use could look like this: \n\n```\n\"Get the financial sentiment of each of the following headlines. {few_shot_examples} The output is strictly limited to [`Positive`, `Negative`, `Neutral`]: {headlines}.\\n{format_instructions}\"\n```\n\nWhen formatting the template, we can pass along `sentiment_examples` to the `few_shot_examples` input variable.\n    \n</p>\n</details>","metadata":{},"id":"7364ebe9-17a1-4888-844c-89efeb3b1c9b","cell_type":"markdown"},{"source":"# Store the few shot examples in a variable.\nsentiment_examples = \"\"\"\n    If a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\n    If the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\n    If nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n\"\"\"\n\n# Instantiate a new prompt template with the format instructions.\nsentiment_template = PromptTemplate(\n    template=\"Get the financial sentiment of each of the following headlines. {few_shot_examples} The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n    input_variables=[\"headlines\", \"few_shot_examples\"],\n    partial_variables={\"format_instructions\": format_instructions}\n)\n\n# Format the template.\nformatted_sentiment_template = sentiment_template.format(headlines=headlines, few_shot_examples=sentiment_examples)\n\n# Invoke the model on the formatted template.\n_output = model.invoke(formatted_sentiment_template)\n\n# Parse the model output.\nsentiments = output_parser.parse(_output)\n\n# Visualize the result.\nvisualize_sentiments(headlines, sentiments)","metadata":{"executionCancelledAt":null,"executionTime":480,"lastExecutedAt":1715609691234,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Store the few shot examples in a variable.\nsentiment_examples = \"\"\"\n    If a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\n    If the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\n    If nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n\"\"\"\n\n# Instantiate a new prompt template with the format instructions.\nsentiment_template = PromptTemplate(\n    template=\"Get the financial sentiment of each of the following headlines. {few_shot_examples} The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n    input_variables=[\"headlines\", \"few_shot_examples\"],\n    partial_variables={\"format_instructions\": format_instructions}\n)\n\n# Format the template.\nformatted_sentiment_template = sentiment_template.format(headlines=headlines, few_shot_examples=sentiment_examples)\n\n# Invoke the model on the formatted template.\n_output = model.invoke(formatted_sentiment_template)\n\n# Parse the model output.\nsentiments = output_parser.parse(_output)\n\n# Visualize the result.\nvisualize_sentiments(headlines, sentiments)","outputsMetadata":{"0":{"height":269,"type":"stream"}}},"id":"78e963c2-d4a5-409b-b4b7-7a1d30a13346","cell_type":"code","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":"POSITIVE: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\nNEGATIVE: Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\nPOSITIVE: Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\nPOSITIVE: Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\nPOSITIVE: Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\nPOSITIVE: Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\n"}]},{"source":"## Task 7: Combining Tools and Output Parsing","metadata":{},"id":"300e7f24-e934-4c49-a710-c67cb3413693","cell_type":"markdown"},{"source":"As you may have noticed in Task 5, using tools is not a guaranteed success. We can improve the performance by clearly determining which tasks can be completed by the Python tool and which we use the GPT-model itself for.\nTo maximize the powerful capabilities of the GPT-model, we prefer its use over hard-coded rule sets when it comes to company name extraction or financial sentiment analysis.\nHowever, other (cumbersome) tasks that do not require the ability to handle ambiguity, are often best left to the Python tool.\n\nLet's ask the model to use the existing lists that we got from our templates (`company_names` and `sentiments`), but use the Python tool to neatly place them in a Pandas dataframe and write them locally to a `.csv` file.\n\nUse the following prompt:\n\n```\nf\"\"\"Create a dataframe with two columns: company_name, sentiment and headline.\n                   To fill the dataframe, use the following lists respectively: {str(company_names)}, {str(sentiments)} and {str(headlines)}. \n                   The dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\n                   If a csv file already exists with the same name, it should be overwritten.\n                   \"\"\"\n```\n\nIn the prompt above, we pass along lists that were generated by the GPT-model before (when it did not have access to the Python tool). Now we only want to give instructions on tasks that should be carried out using Python code, such as the creation of the dataframe, saving (and overwriting) it, ...\n\nKeep in mind that we can use this same way of working for much more complex tasks, that might encompass extensive coding requirements.","metadata":{},"id":"4e447e81-3b31-4e74-a567-53623cc863ce","cell_type":"markdown"},{"source":"### Instructions\n\n- Invoke the `agent_executor` on the prompt above.","metadata":{},"id":"d690b3d5-2602-4c3b-990f-85990d4e301d","cell_type":"markdown"},{"source":"# Invoke the agent to create a file with the headlines, company names and sentiments.\nagent_executor.invoke(f\"\"\"Create a dataframe with two columns: company_name, sentiment and headline.\nTo fill the dataframe, use the following lists respectively: {str(company_names)}, {str(sentiments)} and {str(headlines)}. \nThe dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\nIf a csv file already exists with the same name, it should be overwritten.\n\"\"\")","metadata":{"executionCancelledAt":null,"executionTime":9962,"lastExecutedAt":1715609701196,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Invoke the agent to create a file with the headlines, company names and sentiments.\nagent_executor.invoke(f\"\"\"Create a dataframe with two columns: company_name, sentiment and headline.\nTo fill the dataframe, use the following lists respectively: {str(company_names)}, {str(sentiments)} and {str(headlines)}. \nThe dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\nIf a csv file already exists with the same name, it should be overwritten.\n\"\"\")","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"188e0ab4-1515-49a2-a8db-09582ec5be21","cell_type":"code","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m I need to import the pandas library to create a dataframe.\nAction: Python_REPL\nAction Input: import pandas as pd\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to create the lists for the columns and data.\nAction: Python_REPL\nAction Input: company_name = ['Aktia Group', 'Vaisala Oyj', 'Orion', 'Tiimari', 'Metso Paper', 'Outokumpu Technology']\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to create the list for the sentiment column.\nAction: Python_REPL\nAction Input: sentiment = ['Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive']\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to create the list for the headline column.\nAction: Python_REPL\nAction Input: headline = [\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .', 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .', 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\", 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to import the pandas library to create a dataframe.\nAction: Python_REPL\nAction Input: import pandas as pd\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to create the dataframe using the lists and save it as a csv file.\nAction: Python_REPL\nAction Input: df = pd.DataFrame({'company_name': company_name, 'sentiment': sentiment, 'headline': headline})\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to save the dataframe as a csv file.\nAction: Python_REPL\nAction Input: df.to_csv('financial_analysis_with_parsing.csv', index=False)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer\nFinal Answer: The dataframe has been created and saved as a csv file in the current working directory under the name financial_analysis_with_parsing.csv.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"},{"output_type":"execute_result","data":{"text/plain":"{'input': 'Create a dataframe with two columns: company_name, sentiment and headline.\\nTo fill the dataframe, use the following lists respectively: [\\'Aktia Group\\', \\'Vaisala Oyj\\', \\'Orion\\', \\'Tiimari\\', \\'Metso Paper\\', \\'Outokumpu Technology\\'], [\\'Positive\\', \\'Negative\\', \\'Positive\\', \\'Positive\\', \\'Positive\\', \\'Positive\\'] and [\"Finnish Aktia Group \\'s operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", \\'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\\', \\'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\\', \\'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\\', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries \\' ( SFI ) pulp mill in Sabah , Malaysia .\", \\'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\\']. \\nThe dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\\nIf a csv file already exists with the same name, it should be overwritten.\\n',\n 'output': 'The dataframe has been created and saved as a csv file in the current working directory under the name financial_analysis_with_parsing.csv.'}"},"metadata":{},"execution_count":18}]},{"source":"If we look at our working directory, we will see a new file pop up, called `financial_analysis_with_parsing.csv`.\n\nLet's analyze it and compare against the output from Task 5.","metadata":{},"id":"477b7d8a-2e4e-4f74-8dc1-b538fcd09f23","cell_type":"markdown"},{"source":"### Instructions\n\nLoad and display the new file.\n- Load `financial_analysis_with_parsing.csv` into a dataframe called `df`.\n- Print the dataframe.","metadata":{},"id":"9ed9c0b7-f961-493e-8a38-7143050448f8","cell_type":"markdown"},{"source":"# Load the CSV file into a dataframe.\ndf = pd.read_csv(\"financial_analysis_with_parsing.csv\")\n\n# Print the dataframe.\ndf","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1715609701245,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load the CSV file into a dataframe.\ndf = pd.read_csv(\"financial_analysis_with_parsing.csv\")\n\n# Print the dataframe.\ndf","outputsMetadata":{"0":{"height":50,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"c6655203-823c-42ca-b0e3-d305fae7f70a","nodeType":"const"}}}}},"id":"142e344b-16c6-46fa-996f-3c1da9b52956","cell_type":"code","execution_count":19,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"company_name","type":"string"},{"name":"sentiment","type":"string"},{"name":"headline","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4,5],"company_name":["Aktia Group","Vaisala Oyj","Orion","Tiimari","Metso Paper","Outokumpu Technology"],"sentiment":["Positive","Negative","Positive","Positive","Positive","Positive"],"headline":["Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .","Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .","Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .","Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .","Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .","Finnish Outokumpu Technology has been awarded several new grinding technology contracts ."]}},"total_rows":6,"truncation_type":null},"text/plain":"           company_name  ...                                           headline\n0           Aktia Group  ...  Finnish Aktia Group 's operating profit rose t...\n1           Vaisala Oyj  ...  Finnish measuring equipment maker Vaisala Oyj ...\n2                 Orion  ...  Finnish pharmaceuticals company Orion reports ...\n3               Tiimari  ...  Tiimari , the Finnish retailer , reported to h...\n4           Metso Paper  ...  Finnish Metso Paper has been awarded a contrac...\n5  Outokumpu Technology  ...  Finnish Outokumpu Technology has been awarded ...\n\n[6 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>company_name</th>\n      <th>sentiment</th>\n      <th>headline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aktia Group</td>\n      <td>Positive</td>\n      <td>Finnish Aktia Group 's operating profit rose t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Vaisala Oyj</td>\n      <td>Negative</td>\n      <td>Finnish measuring equipment maker Vaisala Oyj ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Orion</td>\n      <td>Positive</td>\n      <td>Finnish pharmaceuticals company Orion reports ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tiimari</td>\n      <td>Positive</td>\n      <td>Tiimari , the Finnish retailer , reported to h...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Metso Paper</td>\n      <td>Positive</td>\n      <td>Finnish Metso Paper has been awarded a contrac...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Outokumpu Technology</td>\n      <td>Positive</td>\n      <td>Finnish Outokumpu Technology has been awarded ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":19}]},{"source":"## Task 8: Using the OpenAI Moderation API","metadata":{},"id":"50ca52ca-41f3-4aea-bd0a-4862a9465a7a","cell_type":"markdown"},{"source":"The OpenAI API platform also sports a Moderation API, in addition to their model and embeddings APIs. The Moderation API can check whether the prompt contains explicit content and can flag various categories like hate, violence, sexually explicit content and so on. When we are building an application targeting large user bases, it becomes crucial to leverage the Moderation API and filter our input prompts to avoid the complications associated with unethical LLM usage.\n\nTo test the Moderation API, we have a small sample of five comments picked from the `r/WallStreetBets` subreddit, stored in the `reddit_comments.txt` file.\n\nLet's start by reading the text file.","metadata":{},"id":"27cd50c5-43a2-4082-8dde-d92c183d38cd","cell_type":"markdown"},{"source":"### Content warning\n\nIn order to trigger the moderation API, the comments were specifically chosen to be offensive. If you are sensitive to awful content, you may wish to avoid printing and reading the text.\n\nNaturally, neither the project instructor nor DataCamp agrees with the ideas expressed within this text file.","metadata":{},"id":"b05cfef2-ba53-4372-a6f3-c998f1d25164","cell_type":"markdown"},{"source":"### Instructions\n\nRead the text file and store its lines in a variable called `comments`.\n- Open `reddit_comments.txt` as read.\n- Use the `.readlines()` method to store its contents in a list called `comments`.\n- Optionally print the comments.","metadata":{},"id":"4e66ebca-010f-4189-b2fd-3a33ec0b378d","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nHere we can use the same `with open(filename, \"r\") as file:` structure as in Task 1.\n\n</p>\n</details>","metadata":{},"id":"7772dd1f-97c0-4713-8836-e06c859b905f","cell_type":"markdown"},{"source":"# Load the lines of the text file.\nwith open('reddit_comments.txt', 'r') as data:\n    comments = data.readlines()\n\n# Optionally print the comments.\n# comments","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1715609701293,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load the lines of the text file.\nwith open('reddit_comments.txt', 'r') as data:\n    comments = data.readlines()\n\n# Optionally print the comments.\n# comments","lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de"},"id":"a5a029ff-5387-49f7-8a77-e3cdd40e7282","cell_type":"code","execution_count":20,"outputs":[]},{"source":"### Instructions\n\nAnalyze a comment using the Moderation API.\n- Pick a comment from the dataset (using and index between 0 - 4) and store this in a variable called `comment`.\n- Use the `openai` package to define an OpenAI model. Assign to `client`.\n- Use the API by calling the previously defined `client`'s `.moderations.create()` method. For the `input` argument, pass the `comment`. Assign to `moderation_output`.\n- Print the comment and moderation output.","metadata":{},"id":"e3b3e694-2176-4d46-91a2-7c17ef31b980","cell_type":"markdown"},{"source":"# Pick a comment.\ncomment = comments[0]\n\n# Define an OpenAI model. Assign to client.\nclient = openai.OpenAI()\n\n# Send the comment to the Moderation API.\nmoderation_output = client.moderations.create(input=comment)\n\n# Optionally print the comment.\n# print(comment)\n\n# Print the output.\nmoderation_output","metadata":{"executionCancelledAt":null,"executionTime":520,"lastExecutedAt":1715609701813,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Pick a comment.\ncomment = comments[0]\n\n# Define an OpenAI model. Assign to client.\nclient = openai.OpenAI()\n\n# Send the comment to the Moderation API.\nmoderation_output = client.moderations.create(input=comment)\n\n# Optionally print the comment.\n# print(comment)\n\n# Print the output.\nmoderation_output"},"id":"306b2862-bcdb-4e67-add4-c776ddc14c5f","cell_type":"code","execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":"ModerationCreateResponse(id='modr-9OQk9Z9BhFuzW7ExUzxQKMaxV5pgn', model='text-moderation-007', results=[Moderation(categories=Categories(harassment=True, harassment_threatening=False, hate=False, hate_threatening=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_scores=CategoryScores(harassment=0.9698249697685242, harassment_threatening=5.6962966482387856e-05, hate=0.2250063419342041, hate_threatening=1.5335608338773454e-07, self_harm=9.122244648551714e-08, self_harm_instructions=1.5766876515499462e-07, self_harm_intent=2.0730141159219784e-08, sexual=8.78242735780077e-06, sexual_minors=2.3513287317200593e-07, violence=0.00021562023903243244, violence_graphic=4.008067833183304e-07, self-harm=9.122244648551714e-08, sexual/minors=2.3513287317200593e-07, hate/threatening=1.5335608338773454e-07, violence/graphic=4.008067833183304e-07, self-harm/intent=2.0730141159219784e-08, self-harm/instructions=1.5766876515499462e-07, harassment/threatening=5.6962966482387856e-05), flagged=True)])"},"metadata":{},"execution_count":21}]},{"source":"We can analyze the output above to determine whether the comment has been deemed explicit or not. The `\"flagged\"` boolean will show us if any (at least one) category has been flagged, and underneath we can see which categories have been flagged.","metadata":{},"id":"1ec05e3a-144a-4abd-8a1c-02b72e2cb41f","cell_type":"markdown"},{"source":"The moderation scores for each category can be retrieved to explore why the text was flagged as inappropriate. It's slightly tedious code, but can be reused exactly whenever you use the moderation API.","metadata":{},"id":"db84ae1a-3fc2-4990-bdb0-7b98d90aef8c","cell_type":"markdown"},{"source":"# Run this code to see the scores\npd.DataFrame(moderation_output.results[0].dict())[[\"categories\", \"category_scores\"]]","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1715609701869,"lastExecutedByKernel":"1a7fe17d-33d6-4724-abc7-59ff6ef148de","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this code to see the scores\npd.DataFrame(moderation_output.results[0].dict())[[\"categories\", \"category_scores\"]]","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"c6655203-823c-42ca-b0e3-d305fae7f70a","nodeType":"const"}}}}},"id":"d48871a3-156c-4fd5-a40e-e3e918fbc486","cell_type":"code","execution_count":22,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"string"},{"name":"categories","type":"boolean"},{"name":"category_scores","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":["harassment","harassment_threatening","hate","hate_threatening","self_harm","self_harm_instructions","self_harm_intent","sexual","sexual_minors","violence","violence_graphic","self-harm","sexual/minors","hate/threatening","violence/graphic","self-harm/intent","self-harm/instructions","harassment/threatening"],"categories":[true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false],"category_scores":[0.9698249698,0.000056963,0.2250063419,1.534e-7,9.12e-8,1.577e-7,2.07e-8,0.0000087824,2.351e-7,0.0002156202,4.008e-7,9.12e-8,2.351e-7,1.534e-7,4.008e-7,2.07e-8,1.577e-7,0.000056963]}},"total_rows":18,"truncation_type":null},"text/plain":"                        categories  category_scores\nharassment                    True     9.698250e-01\nharassment_threatening       False     5.696297e-05\nhate                         False     2.250063e-01\nhate_threatening             False     1.533561e-07\nself_harm                    False     9.122245e-08\nself_harm_instructions       False     1.576688e-07\nself_harm_intent             False     2.073014e-08\nsexual                       False     8.782427e-06\nsexual_minors                False     2.351329e-07\nviolence                     False     2.156202e-04\nviolence_graphic             False     4.008068e-07\nself-harm                    False     9.122245e-08\nsexual/minors                False     2.351329e-07\nhate/threatening             False     1.533561e-07\nviolence/graphic             False     4.008068e-07\nself-harm/intent             False     2.073014e-08\nself-harm/instructions       False     1.576688e-07\nharassment/threatening       False     5.696297e-05","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>categories</th>\n      <th>category_scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>harassment</th>\n      <td>True</td>\n      <td>9.698250e-01</td>\n    </tr>\n    <tr>\n      <th>harassment_threatening</th>\n      <td>False</td>\n      <td>5.696297e-05</td>\n    </tr>\n    <tr>\n      <th>hate</th>\n      <td>False</td>\n      <td>2.250063e-01</td>\n    </tr>\n    <tr>\n      <th>hate_threatening</th>\n      <td>False</td>\n      <td>1.533561e-07</td>\n    </tr>\n    <tr>\n      <th>self_harm</th>\n      <td>False</td>\n      <td>9.122245e-08</td>\n    </tr>\n    <tr>\n      <th>self_harm_instructions</th>\n      <td>False</td>\n      <td>1.576688e-07</td>\n    </tr>\n    <tr>\n      <th>self_harm_intent</th>\n      <td>False</td>\n      <td>2.073014e-08</td>\n    </tr>\n    <tr>\n      <th>sexual</th>\n      <td>False</td>\n      <td>8.782427e-06</td>\n    </tr>\n    <tr>\n      <th>sexual_minors</th>\n      <td>False</td>\n      <td>2.351329e-07</td>\n    </tr>\n    <tr>\n      <th>violence</th>\n      <td>False</td>\n      <td>2.156202e-04</td>\n    </tr>\n    <tr>\n      <th>violence_graphic</th>\n      <td>False</td>\n      <td>4.008068e-07</td>\n    </tr>\n    <tr>\n      <th>self-harm</th>\n      <td>False</td>\n      <td>9.122245e-08</td>\n    </tr>\n    <tr>\n      <th>sexual/minors</th>\n      <td>False</td>\n      <td>2.351329e-07</td>\n    </tr>\n    <tr>\n      <th>hate/threatening</th>\n      <td>False</td>\n      <td>1.533561e-07</td>\n    </tr>\n    <tr>\n      <th>violence/graphic</th>\n      <td>False</td>\n      <td>4.008068e-07</td>\n    </tr>\n    <tr>\n      <th>self-harm/intent</th>\n      <td>False</td>\n      <td>2.073014e-08</td>\n    </tr>\n    <tr>\n      <th>self-harm/instructions</th>\n      <td>False</td>\n      <td>1.576688e-07</td>\n    </tr>\n    <tr>\n      <th>harassment/threatening</th>\n      <td>False</td>\n      <td>5.696297e-05</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":22}]},{"source":"## Summary","metadata":{},"id":"a137c8cc-937e-4214-b1f1-a8849df2cb8c","cell_type":"markdown"},{"source":"Congratulations on completing this module! You should be able to get started with basic LangChain projects yourself now. \n\nYou've learned:\n- Important prompt engineering tricks and optimizations\n- Setting up prompt templates\n- Using LLMChains\n- Using LangChain output parsing to generate Python objects to be used downstream\n- Using LangChain Agents and Tools to add additional functionalities to generative AI projects\n- Leveraging the Moderation API to act as a filter of user input\n\nWe wish you the best of luck in the following modules!","metadata":{},"id":"0ea79fb4-1efa-44dc-a414-eae8e59d3444","cell_type":"markdown"}],"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}